{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence :  Hello, you just won $50,000!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1500), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1500), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235B005BF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235B005BF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emotion predicted is ham\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "        \n",
    "df_spam = pd.read_csv(\"C:\\deeplearning\\spam_data\\SPAM text message 20170820 - Data.csv\", header=None, sep=\",\", names = [\"Type\", \"Message\"], encoding='utf-8')\n",
    "type_train, message_train = df_spam[\"Type\"], df_spam[\"Message\"]\n",
    "\n",
    "tokenizer=Tokenizer(num_words=df_spam.shape[0])\n",
    "tokenizer.fit_on_texts(message_train)\n",
    "\n",
    "message_token=tokenizer.texts_to_sequences(message_train)\n",
    "token_data=pad_sequences(message_token, maxlen=1500)\n",
    "encode=LabelEncoder()\n",
    "\n",
    "type1=encode.fit_transform(df_spam[\"Type\"])\n",
    "type_data=np_utils.to_categorical(type1)\n",
    "\n",
    "msg_train=token_data[:int(0.85*len(message_train))]\n",
    "msg_val=token_data[int(0.85*len(message_train)):]\n",
    "ty_train=type_data[:int(0.85*len(type_train))]\n",
    "ty_val=type_data[int(0.85*len(type_train)):]\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(message_train), 64, input_length=1500))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stop=EarlyStopping(monitor=\"val_loss\")\n",
    "model.fit(msg_train, ty_train, validation_data=(msg_val, ty_val), epochs=10, callbacks=[early_stop])\n",
    "\n",
    "model.save(\"spam_model.tf\")\n",
    "model = load_model('spam_model.tf')\n",
    "\n",
    "def get_key(value):\n",
    "    dictionary={'ham':0,'spam':1}\n",
    "    for key,val in dictionary.items():\n",
    "          if (val==value):\n",
    "            return key\n",
    "\n",
    "        \n",
    "def predict(sentence):\n",
    "  sentence_lst=[]\n",
    "  sentence_lst.append(sentence)\n",
    "  sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
    "  sentence_padded=pad_sequences(sentence_seq,maxlen=100,padding='post')\n",
    "  ans=get_key(model.predict_classes(sentence_padded))\n",
    "  print(\"The emotion predicted is\",ans)\n",
    "    \n",
    "predict(str(input('Enter a sentence : ')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
